{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['e', 'u', 'y']\n",
    "classes = []\n",
    "data = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    for image in os.listdir(symbol):\n",
    "        array = cv2.imread(symbol + '/' + image, 0)\n",
    "        data.append(array)\n",
    "        if symbol == 'e':\n",
    "            classes.append(0)\n",
    "        elif symbol == 'u':\n",
    "            classes.append(1)\n",
    "        elif symbol == 'y':\n",
    "            classes.append(2)\n",
    "\n",
    "arr_classes = np.array(classes)\n",
    "arr_data = np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80 / 20 split\n",
    "num_train = 480 \n",
    "num_test = 120\n",
    "num_classes = 3\n",
    "height, width, depth = 32, 32, 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(arr_data, arr_classes, test_size = 0.2)\n",
    "\n",
    "x_train = x_train.reshape(num_train, height * width)\n",
    "x_test = x_test.reshape(num_test, height * width)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 \n",
    "x_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes) \n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 12:39:52.204961 140301673613120 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 12:39:52.219289 140301673613120 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 12:39:52.222363 140301673613120 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_in = Input(shape = (height * width,))\n",
    "m_out = Dense(num_classes, activation='softmax')(m_in)\n",
    "model = Model(inputs=m_in, outputs=m_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 12:40:00.330677 140301673613120 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0826 12:40:00.350972 140301673613120 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "\toptimizer='adam', \n",
    "\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,075\n",
      "Trainable params: 3,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 432 samples, validate on 48 samples\n",
      "Epoch 1/50\n",
      "432/432 [==============================] - 0s 43us/step - loss: 0.0617 - acc: 0.9931 - val_loss: 0.1150 - val_acc: 0.9792\n",
      "Epoch 2/50\n",
      "432/432 [==============================] - 0s 43us/step - loss: 0.0607 - acc: 0.9931 - val_loss: 0.1507 - val_acc: 0.9583\n",
      "Epoch 3/50\n",
      "432/432 [==============================] - 0s 53us/step - loss: 0.0575 - acc: 0.9977 - val_loss: 0.1090 - val_acc: 0.9792\n",
      "Epoch 4/50\n",
      "432/432 [==============================] - 0s 54us/step - loss: 0.0529 - acc: 0.9954 - val_loss: 0.1211 - val_acc: 0.9792\n",
      "Epoch 5/50\n",
      "432/432 [==============================] - 0s 34us/step - loss: 0.0557 - acc: 0.9954 - val_loss: 0.1149 - val_acc: 0.9792\n",
      "Epoch 6/50\n",
      "432/432 [==============================] - 0s 32us/step - loss: 0.0525 - acc: 0.9977 - val_loss: 0.1061 - val_acc: 0.9792\n",
      "Epoch 7/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0507 - acc: 0.9977 - val_loss: 0.1061 - val_acc: 0.9792\n",
      "Epoch 8/50\n",
      "432/432 [==============================] - 0s 42us/step - loss: 0.0576 - acc: 0.9954 - val_loss: 0.1217 - val_acc: 0.9583\n",
      "Epoch 9/50\n",
      "432/432 [==============================] - 0s 47us/step - loss: 0.0502 - acc: 0.9954 - val_loss: 0.1030 - val_acc: 0.9792\n",
      "Epoch 10/50\n",
      "432/432 [==============================] - 0s 38us/step - loss: 0.0504 - acc: 0.9977 - val_loss: 0.1116 - val_acc: 0.9792\n",
      "Epoch 11/50\n",
      "432/432 [==============================] - 0s 36us/step - loss: 0.0510 - acc: 0.9954 - val_loss: 0.1196 - val_acc: 0.9792\n",
      "Epoch 12/50\n",
      "432/432 [==============================] - 0s 36us/step - loss: 0.0487 - acc: 0.9954 - val_loss: 0.1072 - val_acc: 0.9792\n",
      "Epoch 13/50\n",
      "432/432 [==============================] - 0s 52us/step - loss: 0.0473 - acc: 0.9977 - val_loss: 0.1107 - val_acc: 0.9792\n",
      "Epoch 14/50\n",
      "432/432 [==============================] - 0s 39us/step - loss: 0.0501 - acc: 0.9954 - val_loss: 0.1161 - val_acc: 0.9792\n",
      "Epoch 15/50\n",
      "432/432 [==============================] - 0s 39us/step - loss: 0.0483 - acc: 0.9977 - val_loss: 0.0997 - val_acc: 0.9792\n",
      "Epoch 16/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0460 - acc: 0.9977 - val_loss: 0.1172 - val_acc: 0.9792\n",
      "Epoch 17/50\n",
      "432/432 [==============================] - 0s 42us/step - loss: 0.0464 - acc: 0.9977 - val_loss: 0.1119 - val_acc: 0.9792\n",
      "Epoch 18/50\n",
      "432/432 [==============================] - 0s 38us/step - loss: 0.0450 - acc: 0.9977 - val_loss: 0.0943 - val_acc: 0.9792\n",
      "Epoch 19/50\n",
      "432/432 [==============================] - 0s 46us/step - loss: 0.0473 - acc: 0.9954 - val_loss: 0.1123 - val_acc: 0.9792\n",
      "Epoch 20/50\n",
      "432/432 [==============================] - 0s 44us/step - loss: 0.0457 - acc: 0.9977 - val_loss: 0.0934 - val_acc: 0.9792\n",
      "Epoch 21/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0436 - acc: 0.9977 - val_loss: 0.1069 - val_acc: 0.9792\n",
      "Epoch 22/50\n",
      "432/432 [==============================] - 0s 42us/step - loss: 0.0424 - acc: 0.9977 - val_loss: 0.1046 - val_acc: 0.9792\n",
      "Epoch 23/50\n",
      "432/432 [==============================] - 0s 31us/step - loss: 0.0429 - acc: 0.9977 - val_loss: 0.0936 - val_acc: 0.9792\n",
      "Epoch 24/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0419 - acc: 0.9977 - val_loss: 0.1040 - val_acc: 0.9792\n",
      "Epoch 25/50\n",
      "432/432 [==============================] - 0s 34us/step - loss: 0.0409 - acc: 0.9977 - val_loss: 0.0962 - val_acc: 0.9792\n",
      "Epoch 26/50\n",
      "432/432 [==============================] - 0s 46us/step - loss: 0.0400 - acc: 0.9977 - val_loss: 0.1110 - val_acc: 0.9792\n",
      "Epoch 27/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0409 - acc: 0.9977 - val_loss: 0.1060 - val_acc: 0.9792\n",
      "Epoch 28/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0398 - acc: 0.9977 - val_loss: 0.0967 - val_acc: 0.9792\n",
      "Epoch 29/50\n",
      "432/432 [==============================] - 0s 31us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9583\n",
      "Epoch 30/50\n",
      "432/432 [==============================] - 0s 46us/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9792\n",
      "Epoch 31/50\n",
      "432/432 [==============================] - 0s 42us/step - loss: 0.0451 - acc: 0.9977 - val_loss: 0.1038 - val_acc: 0.9792\n",
      "Epoch 32/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9792\n",
      "Epoch 33/50\n",
      "432/432 [==============================] - 0s 35us/step - loss: 0.0374 - acc: 0.9977 - val_loss: 0.0910 - val_acc: 0.9792\n",
      "Epoch 34/50\n",
      "432/432 [==============================] - 0s 36us/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9583\n",
      "Epoch 35/50\n",
      "432/432 [==============================] - 0s 34us/step - loss: 0.0407 - acc: 0.9977 - val_loss: 0.0943 - val_acc: 0.9792\n",
      "Epoch 36/50\n",
      "432/432 [==============================] - 0s 35us/step - loss: 0.0378 - acc: 0.9977 - val_loss: 0.0880 - val_acc: 0.9792\n",
      "Epoch 37/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0415 - acc: 0.9977 - val_loss: 0.0923 - val_acc: 0.9792\n",
      "Epoch 38/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 0.9792\n",
      "Epoch 39/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9792\n",
      "Epoch 40/50\n",
      "432/432 [==============================] - 0s 32us/step - loss: 0.0356 - acc: 0.9977 - val_loss: 0.0921 - val_acc: 0.9792\n",
      "Epoch 41/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9792\n",
      "Epoch 42/50\n",
      "432/432 [==============================] - 0s 50us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9792\n",
      "Epoch 43/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9792\n",
      "Epoch 44/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.0356 - acc: 0.9977 - val_loss: 0.0936 - val_acc: 0.9792\n",
      "Epoch 45/50\n",
      "432/432 [==============================] - 0s 44us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9792\n",
      "Epoch 46/50\n",
      "432/432 [==============================] - 0s 49us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9792\n",
      "Epoch 47/50\n",
      "432/432 [==============================] - 0s 42us/step - loss: 0.0398 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9583\n",
      "Epoch 48/50\n",
      "432/432 [==============================] - 0s 35us/step - loss: 0.0380 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9792\n",
      "Epoch 49/50\n",
      "432/432 [==============================] - 0s 36us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9792\n",
      "Epoch 50/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0911 - val_acc: 0.9792\n",
      "120/120 [==============================] - 0s 49us/step\n",
      "Loss = 0.0909841805696, Accuracy = 0.958333337307\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=32, epochs=50, \n",
    "         verbose=1, validation_split=0.1)\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Loss = {}, Accuracy = {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_in = Input(shape = (height * width,))\n",
    "hidden_1 = Dense(10, activation='relu')(m_in) \n",
    "hidden_2 = Dense(10, activation='relu')(hidden_1)\n",
    "m_out = Dense(num_classes, activation='softmax')(hidden_2)\n",
    "model = Model(inputs=m_in, outputs=m_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "\toptimizer='adam', \n",
    "\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 10,393\n",
      "Trainable params: 10,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 432 samples, validate on 48 samples\n",
      "Epoch 1/50\n",
      "432/432 [==============================] - 0s 508us/step - loss: 1.1007 - acc: 0.2824 - val_loss: 1.0984 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "432/432 [==============================] - 0s 40us/step - loss: 1.0819 - acc: 0.3611 - val_loss: 1.0499 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "432/432 [==============================] - 0s 43us/step - loss: 1.0637 - acc: 0.4375 - val_loss: 1.0331 - val_acc: 0.5417\n",
      "Epoch 4/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 1.0302 - acc: 0.4815 - val_loss: 0.9872 - val_acc: 0.3750\n",
      "Epoch 5/50\n",
      "432/432 [==============================] - 0s 40us/step - loss: 1.0095 - acc: 0.4838 - val_loss: 0.9701 - val_acc: 0.3750\n",
      "Epoch 6/50\n",
      "432/432 [==============================] - 0s 40us/step - loss: 0.9829 - acc: 0.5023 - val_loss: 0.9434 - val_acc: 0.4375\n",
      "Epoch 7/50\n",
      "432/432 [==============================] - 0s 40us/step - loss: 0.9559 - acc: 0.5370 - val_loss: 0.9236 - val_acc: 0.5208\n",
      "Epoch 8/50\n",
      "432/432 [==============================] - 0s 37us/step - loss: 0.9334 - acc: 0.5741 - val_loss: 0.9044 - val_acc: 0.4583\n",
      "Epoch 9/50\n",
      "432/432 [==============================] - 0s 42us/step - loss: 0.9190 - acc: 0.5648 - val_loss: 0.8874 - val_acc: 0.5208\n",
      "Epoch 10/50\n",
      "432/432 [==============================] - 0s 63us/step - loss: 0.8888 - acc: 0.6019 - val_loss: 0.8728 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "432/432 [==============================] - 0s 39us/step - loss: 0.8731 - acc: 0.5972 - val_loss: 0.8544 - val_acc: 0.5417\n",
      "Epoch 12/50\n",
      "432/432 [==============================] - 0s 46us/step - loss: 0.8540 - acc: 0.6273 - val_loss: 0.8437 - val_acc: 0.5625\n",
      "Epoch 13/50\n",
      "432/432 [==============================] - 0s 44us/step - loss: 0.8381 - acc: 0.6227 - val_loss: 0.8310 - val_acc: 0.5417\n",
      "Epoch 14/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.8155 - acc: 0.6435 - val_loss: 0.8123 - val_acc: 0.5625\n",
      "Epoch 15/50\n",
      "432/432 [==============================] - 0s 41us/step - loss: 0.7970 - acc: 0.6551 - val_loss: 0.7978 - val_acc: 0.5625\n",
      "Epoch 16/50\n",
      "432/432 [==============================] - 0s 59us/step - loss: 0.7865 - acc: 0.6644 - val_loss: 0.7838 - val_acc: 0.5625\n",
      "Epoch 17/50\n",
      "432/432 [==============================] - 0s 47us/step - loss: 0.7824 - acc: 0.6458 - val_loss: 0.7887 - val_acc: 0.6250\n",
      "Epoch 18/50\n",
      "432/432 [==============================] - 0s 39us/step - loss: 0.7748 - acc: 0.6366 - val_loss: 0.7615 - val_acc: 0.5625\n",
      "Epoch 19/50\n",
      "432/432 [==============================] - 0s 49us/step - loss: 0.7440 - acc: 0.6551 - val_loss: 0.7501 - val_acc: 0.6458\n",
      "Epoch 20/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.7226 - acc: 0.6852 - val_loss: 0.7310 - val_acc: 0.5833\n",
      "Epoch 21/50\n",
      "432/432 [==============================] - 0s 38us/step - loss: 0.7090 - acc: 0.6782 - val_loss: 0.7210 - val_acc: 0.6250\n",
      "Epoch 22/50\n",
      "432/432 [==============================] - 0s 43us/step - loss: 0.6955 - acc: 0.7083 - val_loss: 0.7184 - val_acc: 0.5625\n",
      "Epoch 23/50\n",
      "432/432 [==============================] - 0s 52us/step - loss: 0.6847 - acc: 0.7106 - val_loss: 0.7104 - val_acc: 0.6667\n",
      "Epoch 24/50\n",
      "432/432 [==============================] - 0s 47us/step - loss: 0.6673 - acc: 0.7106 - val_loss: 0.6847 - val_acc: 0.6042\n",
      "Epoch 25/50\n",
      "432/432 [==============================] - 0s 62us/step - loss: 0.6525 - acc: 0.7106 - val_loss: 0.7297 - val_acc: 0.6875\n",
      "Epoch 26/50\n",
      "432/432 [==============================] - 0s 40us/step - loss: 0.6515 - acc: 0.7245 - val_loss: 0.6607 - val_acc: 0.6250\n",
      "Epoch 27/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.6437 - acc: 0.7384 - val_loss: 0.6506 - val_acc: 0.6458\n",
      "Epoch 28/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.6117 - acc: 0.7245 - val_loss: 0.6401 - val_acc: 0.6458\n",
      "Epoch 29/50\n",
      "432/432 [==============================] - 0s 46us/step - loss: 0.5994 - acc: 0.7407 - val_loss: 0.6534 - val_acc: 0.7292\n",
      "Epoch 30/50\n",
      "432/432 [==============================] - 0s 51us/step - loss: 0.5948 - acc: 0.7407 - val_loss: 0.6156 - val_acc: 0.6458\n",
      "Epoch 31/50\n",
      "432/432 [==============================] - 0s 50us/step - loss: 0.5759 - acc: 0.7500 - val_loss: 0.6034 - val_acc: 0.6458\n",
      "Epoch 32/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.5755 - acc: 0.7685 - val_loss: 0.5978 - val_acc: 0.7292\n",
      "Epoch 33/50\n",
      "432/432 [==============================] - 0s 41us/step - loss: 0.5611 - acc: 0.7593 - val_loss: 0.5909 - val_acc: 0.6458\n",
      "Epoch 34/50\n",
      "432/432 [==============================] - 0s 63us/step - loss: 0.5432 - acc: 0.7847 - val_loss: 0.5895 - val_acc: 0.8125\n",
      "Epoch 35/50\n",
      "432/432 [==============================] - 0s 69us/step - loss: 0.5317 - acc: 0.7894 - val_loss: 0.5704 - val_acc: 0.6458\n",
      "Epoch 36/50\n",
      "432/432 [==============================] - 0s 49us/step - loss: 0.5289 - acc: 0.8032 - val_loss: 0.5623 - val_acc: 0.8333\n",
      "Epoch 37/50\n",
      "432/432 [==============================] - 0s 68us/step - loss: 0.5250 - acc: 0.7963 - val_loss: 0.5749 - val_acc: 0.6250\n",
      "Epoch 38/50\n",
      "432/432 [==============================] - 0s 57us/step - loss: 0.5308 - acc: 0.7917 - val_loss: 0.5545 - val_acc: 0.8125\n",
      "Epoch 39/50\n",
      "432/432 [==============================] - 0s 51us/step - loss: 0.4898 - acc: 0.8218 - val_loss: 0.5440 - val_acc: 0.8125\n",
      "Epoch 40/50\n",
      "432/432 [==============================] - 0s 46us/step - loss: 0.5023 - acc: 0.8148 - val_loss: 0.5279 - val_acc: 0.8542\n",
      "Epoch 41/50\n",
      "432/432 [==============================] - 0s 54us/step - loss: 0.4799 - acc: 0.8519 - val_loss: 0.5162 - val_acc: 0.7917\n",
      "Epoch 42/50\n",
      "432/432 [==============================] - 0s 41us/step - loss: 0.4695 - acc: 0.8356 - val_loss: 0.5147 - val_acc: 0.8542\n",
      "Epoch 43/50\n",
      "432/432 [==============================] - 0s 61us/step - loss: 0.4626 - acc: 0.8843 - val_loss: 0.4992 - val_acc: 0.8750\n",
      "Epoch 44/50\n",
      "432/432 [==============================] - 0s 44us/step - loss: 0.4467 - acc: 0.8611 - val_loss: 0.4999 - val_acc: 0.8750\n",
      "Epoch 45/50\n",
      "432/432 [==============================] - 0s 48us/step - loss: 0.4396 - acc: 0.8773 - val_loss: 0.4820 - val_acc: 0.8542\n",
      "Epoch 46/50\n",
      "432/432 [==============================] - 0s 57us/step - loss: 0.4314 - acc: 0.8727 - val_loss: 0.4746 - val_acc: 0.8542\n",
      "Epoch 47/50\n",
      "432/432 [==============================] - 0s 47us/step - loss: 0.4324 - acc: 0.8866 - val_loss: 0.4916 - val_acc: 0.8750\n",
      "Epoch 48/50\n",
      "432/432 [==============================] - 0s 41us/step - loss: 0.4266 - acc: 0.8866 - val_loss: 0.4647 - val_acc: 0.8542\n",
      "Epoch 49/50\n",
      "432/432 [==============================] - 0s 45us/step - loss: 0.4262 - acc: 0.8611 - val_loss: 0.4695 - val_acc: 0.8958\n",
      "Epoch 50/50\n",
      "432/432 [==============================] - 0s 47us/step - loss: 0.5165 - acc: 0.7847 - val_loss: 0.5417 - val_acc: 0.8333\n",
      "120/120 [==============================] - 0s 25us/step\n",
      "Loss = 0.482520659765, Accuracy = 0.841666666667\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=32, epochs=50, \n",
    "         verbose=1, validation_split=0.1)\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Loss = {}, Accuracy = {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
