{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['e', 'u', 'y']\n",
    "classes = []\n",
    "data = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    for image in os.listdir(symbol):\n",
    "        array = cv2.imread(symbol + '/' + image, 0)\n",
    "        data.append(array)\n",
    "        if symbol == 'e':\n",
    "            classes.append(0)\n",
    "        elif symbol == 'u':\n",
    "            classes.append(1)\n",
    "        elif symbol == 'y':\n",
    "            classes.append(2)\n",
    "\n",
    "arr_classes = np.array(classes)\n",
    "arr_data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 480 \n",
    "num_test = 120\n",
    "num_classes = 3\n",
    "height, width, depth = 32, 32, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (480, 32, 32, 1))\n",
      "(480, 'train samples')\n",
      "(120, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(arr_data, arr_classes, test_size = 0.2)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], depth, height, width)\n",
    "    x_test = x_test.reshape(x_test.shape[0], depth, height, width)\n",
    "    input_shape = (depth, height, width)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], height, width, depth)\n",
    "    x_test = x_test.reshape(x_test.shape[0], height, width, depth)\n",
    "    input_shape = (height, width, depth)\n",
    "    \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 12:44:34.110824 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 12:44:34.127569 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 12:44:34.130172 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0826 12:44:34.155004 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0826 12:44:34.157677 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0826 12:44:34.166368 140011265042240 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 12:44:42.207598 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0826 12:44:42.214214 140011265042240 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 12:44:47.196475 140011265042240 deprecation.py:323] From /home/ezrafell/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 120 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 1.1344 - acc: 0.4813 - val_loss: 0.8106 - val_acc: 0.8083\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.5415 - acc: 0.8250 - val_loss: 0.2276 - val_acc: 0.9583\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.1967 - acc: 0.9437 - val_loss: 0.0830 - val_acc: 0.9750\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0983 - acc: 0.9729 - val_loss: 0.0445 - val_acc: 0.9917\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0799 - acc: 0.9771 - val_loss: 0.0363 - val_acc: 0.9917\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0427 - acc: 0.9917 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0252 - acc: 0.9979 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0141 - acc: 0.9958 - val_loss: 0.0180 - val_acc: 0.9917\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.9979 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.6392e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.1394e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.0318e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 4.4156e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 4.4589e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.9456e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 3.8387e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 6.6698e-04 - acc: 1.0000 - val_loss: 5.1333e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.7528e-04 - acc: 1.0000 - val_loss: 6.2253e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.9979 - val_loss: 2.9656e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 3.5252e-04 - acc: 1.0000 - val_loss: 2.8063e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 4.7853e-04 - acc: 1.0000 - val_loss: 2.2918e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 8.1713e-04 - acc: 1.0000 - val_loss: 4.1648e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 8.6559e-04 - acc: 1.0000 - val_loss: 1.6039e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 0.9979 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 6.0200e-04 - acc: 1.0000 - val_loss: 3.4855e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 5.6772e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.8962e-04 - acc: 1.0000 - val_loss: 6.3255e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.5638e-04 - acc: 1.0000 - val_loss: 3.8908e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 7.9214e-04 - acc: 1.0000 - val_loss: 1.0720e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 3.7730e-04 - acc: 1.0000 - val_loss: 2.0200e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.3715e-04 - acc: 1.0000 - val_loss: 2.0334e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 1.0232e-04 - acc: 1.0000 - val_loss: 1.5063e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 1.3395e-04 - acc: 1.0000 - val_loss: 1.6493e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 6.1105e-05 - acc: 1.0000 - val_loss: 1.4832e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.5435e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.7001e-04 - acc: 1.0000 - val_loss: 4.1514e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 2.4497e-04 - acc: 1.0000 - val_loss: 1.6805e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 8.3890e-05 - acc: 1.0000 - val_loss: 1.3210e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 4.9979e-05 - acc: 1.0000 - val_loss: 1.3007e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 1.9309e-04 - acc: 1.0000 - val_loss: 9.3471e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 9.1804e-05 - acc: 1.0000 - val_loss: 3.3745e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "480/480 [==============================] - 1s 2ms/step - loss: 5.9926e-05 - acc: 1.0000 - val_loss: 3.3228e-04 - val_acc: 1.0000\n",
      "('Loss:', 0.0003322779470181558)\n",
      "('Accuracy:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32, epochs=50,\n",
    "          verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
